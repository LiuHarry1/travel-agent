"""
å‘½ä»¤è¡Œæµ‹è¯•å…¥å£ - ChatGPT/è±†åŒ…é£æ ¼çš„æ™ºèƒ½å¯¹è¯
æ¼”ç¤ºæµå¼è¾“å‡ºä¸­åˆ¤æ–­æ˜¯å¦ä½¿ç”¨ function call
"""
import asyncio
import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from openai import OpenAI
from agent import ChatAgent
from tools import TOOLS

# é…ç½®æ—¥å¿—
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def create_client() -> OpenAI:
    """
    åˆ›å»º OpenAI å®¢æˆ·ç«¯
    æ”¯æŒåˆ‡æ¢ Qwenï¼ˆè±†åŒ…ï¼‰å’Œ GPT-4
    """
    # ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
    provider = os.getenv("LLM_PROVIDER", "qwen").lower()
    
    if provider == "qwen":
        # Qwen (DashScope) - è±†åŒ…èƒŒååŒæ¬¾ API
        api_key = os.getenv("DASHSCOPE_API_KEY") or os.getenv("QWEN_API_KEY")
        if not api_key:
            raise ValueError("è¯·è®¾ç½®ç¯å¢ƒå˜é‡ DASHSCOPE_API_KEY æˆ– QWEN_API_KEY")
        
        base_url = "https://dashscope.aliyuncs.com/compatible-mode/v1"
        model = os.getenv("QWEN_MODEL", "qwen-plus")
        logger.info(f"ä½¿ç”¨ Qwen (DashScope) API, æ¨¡å‹: {model}")
        
    elif provider == "openai":
        # OpenAI GPT-4/5
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("è¯·è®¾ç½®ç¯å¢ƒå˜é‡ OPENAI_API_KEY")
        
        base_url = "https://api.openai.com/v1"
        model = os.getenv("OPENAI_MODEL", "gpt-4")
        logger.info(f"ä½¿ç”¨ OpenAI API, æ¨¡å‹: {model}")
        
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„ provider: {provider}ï¼Œè¯·ä½¿ç”¨ 'qwen' æˆ– 'openai'")
    
    client = OpenAI(
        api_key=api_key,
        base_url=base_url
    )
    
    return client, model


async def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸš€ ChatGPT/è±†åŒ…é£æ ¼æ™ºèƒ½å¯¹è¯ç³»ç»Ÿ")
    print("æ”¯æŒæµå¼è¾“å‡º + è‡ªåŠ¨å·¥å…·è°ƒç”¨")
    print("=" * 60)
    print()
    
    try:
        # åˆ›å»ºå®¢æˆ·ç«¯å’Œ Agent
        client, model = create_client()
        agent = ChatAgent(model=model, client=client)
        
        # æ³¨å†Œæ‰€æœ‰å·¥å…·
        print(f"ğŸ“¦ æ³¨å†Œ {len(TOOLS)} ä¸ªå·¥å…·:")
        for name, info in TOOLS.items():
            agent.register_tool(name, info["schema"], info["function"])
            print(f"  - {name}: {info['schema'].get('description', '')[:50]}")
        print()
        
        print("ğŸ’¬ å¼€å§‹å¯¹è¯ (è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡º, 'reset' é‡ç½®å¯¹è¯å†å²)")
        print("-" * 60)
        
        while True:
            try:
                # è·å–ç”¨æˆ·è¾“å…¥
                user_input = input("\nğŸ‘¤ You: ").strip()
                
                if not user_input:
                    continue
                
                if user_input.lower() in ['quit', 'exit', 'q']:
                    print("ğŸ‘‹ å†è§ï¼")
                    break
                
                if user_input.lower() == 'reset':
                    agent.reset_conversation()
                    print("âœ… å¯¹è¯å†å²å·²é‡ç½®")
                    continue
                
                # æµå¼å¯¹è¯
                print("\nğŸ¤– AI: ", end="", flush=True)
                
                accumulated_text = ""
                tool_called = False
                
                async for content, tool_info in agent.chat_stream(user_input):
                    if tool_info:
                        # å·¥å…·è°ƒç”¨
                        if tool_info.get("type") == "tool_result":
                            print(f"\n\n[âœ… å·¥å…·æ‰§è¡Œå®Œæˆ: {tool_info['name']}]")
                            print(f"[ç»“æœ: {tool_info['result'][:100]}...]")
                            print("\nğŸ¤– AI: ", end="", flush=True)
                            tool_called = True
                        elif tool_info.get("type") == "tool_error":
                            print(f"\n\n[âŒ å·¥å…·æ‰§è¡Œé”™è¯¯: {tool_info.get('error', 'Unknown error')}]")
                        else:
                            # æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨
                            print(f"\n\n[ğŸ”§ æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨: {tool_info['name']}]")
                            print(f"[å‚æ•°: {tool_info['args']}]")
                            print("[æ‰§è¡Œä¸­...]")
                            tool_called = True
                    elif content:
                        # æ™®é€šæ–‡æœ¬å†…å®¹
                        print(content, end="", flush=True)
                        accumulated_text += content
                
                if not tool_called and accumulated_text:
                    print()  # æ¢è¡Œ
                
                print()  # é¢å¤–æ¢è¡Œ
                
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ å†è§ï¼")
                break
            except Exception as e:
                logger.error(f"Error in conversation: {e}", exc_info=True)
                print(f"\nâŒ é”™è¯¯: {str(e)}")
                
    except Exception as e:
        logger.error(f"Failed to initialize: {e}", exc_info=True)
        print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        print("\næç¤º:")
        print("  1. è®¾ç½®ç¯å¢ƒå˜é‡: export DASHSCOPE_API_KEY=your_key (Qwen)")
        print("  æˆ–: export OPENAI_API_KEY=your_key (OpenAI)")
        print("  2. å¯é€‰: export LLM_PROVIDER=qwen æˆ– openai")
        print("  3. å¯é€‰: export QWEN_MODEL=qwen-plus")


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ å†è§ï¼")

